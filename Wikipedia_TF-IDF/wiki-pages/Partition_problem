Given S = {3,1,1,2,2,1}, a valid solution to the partition problem is the two sets S = {1,1,1,2} and S = {2,3}. Both sets sum to 5, and they partition S. Note that this solution is not unique. S = {3,1,1} and S = {2,2,1} is another solution.

Not every multiset of positive integers has a partition into two halves with equal sum. An example of such a set is S = {2,5}.

The problem can be solved using dynamic programming when the size of the set and the size of the sum of the integers in the set are not too big to render the storage requirements infeasible.

Suppose the input to the algorithm is a list of the form:

Let N be the number of elements in S. Let K be the sum of all elements in S. That is: K = x + ... + x . We will build an algorithm that determines if there is a subset of S that sums to . If there is a subset, then:

We wish to determine if there is a subset of S that sums to . Let:

Then p( , n) is True if and only if there is a subset of S that sums to . The goal of our algorithm will be to compute p( , n). In aid of this, we have the following recurrence relation:

The reasoning for this is as follows: there is some subset of S that sums to i using numbers

if and only if either of the following is true:

The algorithm is to build up a table of size by n containing the values of the recurrence. Remember K is the size of the sum, while N is the number of elements. Once the entire table is filled in, return P( , n). Below is a picture of the table P. There is a purple arrow from one block to another if the value of the target-block might depend on the value of the source-block. This dependence is a property of the recurrence relation.

Below is the table P for the example set used above S = {3, 1, 1, 2, 2, 1}:

This algorithm runs in time O(K N), where N is the number of elements in the input set and K is the sum of elements in the input set.

The algorithm can be extended to the k-way multi-partitioning problem, but then takes O(n(k  1)mk  1) memory where m is the largest number in the input, making it impractical even for k = 3 unless the inputs are very small numbers.[1]

The partition problem can be viewed as a special case of the subset sum problem and the pseudo-polynomial time dynamic programming solution given above generalizes to a solution for the subset sum problem.

Several heuristic algorithms exist to produce approximations to the partition optimization problem. These can be extended to linear-space exact algorithms.[1]

One approach to the problem, imitating the way children choose teams for a game, is the greedy algorithm, which iterates through the numbers in descending order, assigning each of them to whichever subset has the smaller sum. This approach has a running time of O(n log n). This heuristic works well in practice when the numbers in the set are of about the same size as its cardinality or less, but it is not guaranteed to produce the best possible partition. For example, given the set S = {4, 5, 6, 7, 8} as input, this greedy algorithm would partition S into subsets {4, 5, 8} and {6, 7}; however, S has an exactly balanced partition into subsets {7, 8} and {4, 5, 6}.

This greedy approach is known to give a 7 -approximation to the optimal solution of the optimization version; that is, if the greedy algorithm outputs two sets A and B, then max(A, B)  7/6 OPT, where OPT is the size of the larger set in the best possible partition.[2] Below is an example (written in Python) for the greedy algorithm.

This algorithm can be extended to the case of k > 2 sets: to take the k largest elements, and for each partition of them, extends the partition by adding the remaining elements successively to whichever set is smaller. (The simple version above corresponds to k = 2.) This version runs in time O(2k n2) and is known to give a (k + 2)/(k + 1) approximation.[2] hus, we have a polynomial-time approximation scheme (PTAS) for the number partition problem, though this is not a fully polynomial time approximation scheme (the running time is exponential in the desired approximation guarantee). However, there are variations of this idea that are fully polynomial-time approximation schemes for the subset-sum problem, and hence for the partition problem as well.[3][4]

Another heuristic is the largest differencing method (LDM),[5] also called the KarmarkarKarp heuristic[1] after the pair of scientists that published it in 1982.[6] LDM operates in two phases. The first phase of the algorithm takes the two largest numbers from the input and replaces them by their difference; this is repeated until only one number remains. The replacement represents the decision to put the two numbers in different sets, without immediately deciding which one is in which set. At the end of phase one, the single remaining number is the difference of the two subset sums. The second phase reconstructs the actual solution.[7]

The differencing heuristic performs better than the greedy one, but is still bad for instances where the numbers are exponential in the size of the set.[7]

The following Java code implements the first phase of KarmarkarKarp. It uses a heap to efficiently find the pair of largest remaining numbers.

There are also anytime algorithms, based on the differencing heuristic, that first find the solution returned by the differencing heuristic, then find progressively better solutions as time allows (possibly requiring exponential time to reach optimality, for the worst instances).[8]

Sets with only one, or no partitions tend to be hardest (or most expensive) to solve compared to their input sizes. When the values are small compared to the size of the set, perfect partitions are more likely. The problem is known to undergo a "phase transition"; being likely for some sets and unlikely for others. If m is the number of bits needed to express any number in the set and n is the size of the set then tends to have many solutions and tends to have few or no solutions. As n and m get larger, the probability of a perfect partition goes to 1 or 0 respectively. This was originally argued based on empirical evidence by Gent and Walsh,[9] then using methods from statistical physics by Mertens,[10] and later proved by Borgs, Chayes, and Pittel.[11]

There is a problem called the 3-partition problem which is to partition the set S into |S|/3 triples each with the same sum. This problem is quite different than the partition problem and has no pseudo-polynomial time algorithm unless P = NP.[12]

The multi-way partition problem generalizes the optimization version of the partition problem. Here, the goal is to divide a set or multiset of n integers into a given number k of subsets, minimizing the difference between the smallest and the largest subset sums.[1]

For further generalizations of the partition problem, see the Bin packing problem.

A related problem, somewhat similar to the Birthday paradox, is that of determining the size of the input set so that we have a probability of one half that there is a solution, under the assumption that each element in the set is randomly selected with uniform distribution between 1 and some given value.

The solution to this problem can be counter-intuitive, like the birthday paradox. For example, with elements randomly selected in between 1 and one million, many people's intuition is that the answer is in the thousands, tens, or even hundreds of thousands, whereas the correct answer is approximately 23 (see Birthday problem Partition problem for details).